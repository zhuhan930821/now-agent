# app.py
import streamlit as st
import os
import sys
from llama_index.core import StorageContext, load_index_from_storage, Settings
from llama_index.llms.gemini import Gemini
from llama_index.embeddings.gemini import GeminiEmbedding
from llama_index.core.memory import ChatMemoryBuffer

# --- é…ç½®éƒ¨åˆ† ---
GOOGLE_API_KEY = "AIzaSyAfgLQT8ZsklX5Xxsk7Mdtyo2wLEf6VAj8"

# é¡µé¢è®¾ç½®
st.set_page_config(page_title="Now Agent", page_icon="ğŸŒ¿", layout="centered")
st.title("ğŸŒ¿ The Power of Now Â· ç–—æ„ˆ Agent")

# --- æ ¸å¿ƒé€»è¾‘ ---

# 1. é…ç½®æ¨¡å‹ (å¿…é¡»è¦æœ‰ï¼Œå¦åˆ™èŠå¤©æ—¶ä¼šä¸çŸ¥é“ç”¨è°)
# æ³¨æ„ï¼šè¿™é‡Œä¸éœ€è¦å†å»ºç«‹ç´¢å¼•ï¼Œåªéœ€è¦é…ç½®å¥½è®© LlamaIndex çŸ¥é“ç”¨ Gemini å›ç­”
Settings.llm = Gemini(
    model="gemini-3-flash-preview", 
    api_key=GOOGLE_API_KEY,
    temperature=0.3
)
Settings.embed_model = GeminiEmbedding(
    model_name="gemini-embedding-001", 
    api_key=GOOGLE_API_KEY
)

# 2. åŠ è½½ç´¢å¼• (åªä»ç¡¬ç›˜è¯»ï¼Œä¸è°ƒ APIï¼Œä¸èŠ±é’±)
@st.cache_resource(show_spinner=False)
def load_index():
    persist_dir = "./storage"
    if not os.path.exists(persist_dir):
        st.error("âŒ æ‰¾ä¸åˆ°ç´¢å¼•æ–‡ä»¶ï¼è¯·å…ˆè¿è¡Œ 'python build_index.py' æ¥æ„å»ºçŸ¥è¯†åº“ã€‚")
        return None
    
    with st.spinner("æ­£åœ¨è¿æ¥å†…åœ¨æ™ºæ…§ (ä»ç¡¬ç›˜åŠ è½½)..."):
        storage_context = StorageContext.from_defaults(persist_dir=persist_dir)
        index = load_index_from_storage(storage_context)
        return index

# --- å¯¼å¸ˆäººæ ¼è®¾å®š ---
SYSTEM_PROMPT = """
ä½ ç°åœ¨æ˜¯ Eckhart Tolleï¼ˆåŸƒå…‹å“ˆç‰¹Â·æ‰˜åˆ©ï¼‰ï¼Œã€Šå½“ä¸‹çš„åŠ›é‡ã€‹çš„ä½œè€…ã€‚
ä½ çš„ä»»åŠ¡ä¸æ˜¯ä½œä¸ºä¸€ä¸ªâ€œAIåŠ©æ‰‹â€å»è§£å†³é€»è¾‘é—®é¢˜ï¼Œè€Œæ˜¯ä½œä¸ºä¸€ä¸ªâ€œçµæ€§å¯¼å¸ˆâ€å»åŒ–è§£ç”¨æˆ·çš„ç—›è‹¦ï¼ˆPain-Bodyï¼‰ã€‚

è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š
1. **æ ¸å¿ƒç«‹åœº**ï¼šæ°¸è¿œå°†ç”¨æˆ·å¼•å¯¼å›â€œå½“ä¸‹â€ï¼ˆThe Nowï¼‰ã€‚æŒ‡å‡ºä»–ä»¬çš„ç—›è‹¦æ¥è‡ªäºâ€œæ€ç»´è®¤åŒâ€ï¼ˆIdentification with the mindï¼‰æˆ–â€œå¿ƒç†æ—¶é—´â€ï¼ˆPsychological timeï¼‰ã€‚
2. **è¯­æ°”é£æ ¼**ï¼šå¹³é™ã€å¯Œæœ‰åŒç†å¿ƒã€æ·±é‚ƒã€ä¸è¯„åˆ¤ã€‚åƒä¸€ä¸ªç¿æ™ºçš„è§‚å¯Ÿè€…ã€‚
3. **å¼•ç”¨åŸæ–‡**ï¼šåœ¨å›ç­”æ—¶ï¼Œå¿…é¡»ä¼˜å…ˆæ£€ç´¢å¹¶å¼•ç”¨ã€Šå½“ä¸‹çš„åŠ›é‡ã€‹ä¹¦ä¸­çš„æ¦‚å¿µï¼ˆå¦‚ï¼šç—›è‹¦ä¹‹èº«ã€å°æˆ‘ã€ä¸´åœ¨ã€æœªæ˜¾åŒ–çŠ¶æ€ï¼‰ã€‚
4. **å®è·µå¯¼å‘**ï¼šä¸è¦åªè®²å¤§é“ç†ï¼Œè¦ç»™å‡ºå…·ä½“çš„ç»ƒä¹ å»ºè®®ï¼ˆä¾‹å¦‚ï¼šå…³æ³¨å‘¼å¸ã€æ„Ÿå—å†…åœ¨èº«ä½“ã€é€šè¿‡è§‚å¯Ÿæƒ…ç»ªæ¥é€šè¿‡å®ƒï¼‰ã€‚
5. **å¤„ç†ç—›è‹¦**ï¼šå½“ç”¨æˆ·è¡¨è¾¾ç—›è‹¦æ—¶ï¼Œä¸è¦è¯•å›¾ç”¨é€»è¾‘å»â€œä¿®è¡¥â€é‚£ä¸ªæ•…äº‹ï¼Œè€Œæ˜¯è®©ä»–ä»¬å»â€œè§‚å¯Ÿâ€é‚£ä¸ªç—›è‹¦ï¼Œä»ç—›è‹¦ä¸­åˆ†ç¦»å‡ºæ¥ã€‚

å¦‚æœç”¨æˆ·é—®éçµæ€§é—®é¢˜ï¼Œè¯·ç¤¼è²Œåœ°å°†è¯é¢˜å¼•å›åˆ°æ„è¯†å’Œå½“ä¸‹çš„å±‚é¢ã€‚
"""
# --- åˆå§‹åŒ– ---
index = load_index()

if index:
    if "chat_engine" not in st.session_state:
        memory = ChatMemoryBuffer.from_defaults(token_limit=3000)
        st.session_state.chat_engine = index.as_chat_engine(
            chat_mode="context",
            memory=memory,
            system_prompt=SYSTEM_PROMPT,
            verbose=False
        )

    # --- èŠå¤©ç•Œé¢ (å’Œä¹‹å‰ä¸€æ ·) ---
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("æ­¤åˆ»ï¼Œä½ æ„Ÿå—åˆ°äº†ä»€ä¹ˆï¼Ÿ"):
        # 1. æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # 2. ç”Ÿæˆå›ç­”
        with st.chat_message("assistant"):
            # è·å–å“åº”å¯¹è±¡ (è¿™é‡Œé¢åŒ…å«äº† text å’Œ source_nodes)
            response = st.session_state.chat_engine.stream_chat(prompt)
            
            # å®æ—¶æµå¼è¾“å‡ºæ–‡å­—
            full_response = st.write_stream(response.response_gen)
            
            # --- ã€æ–°åŠ çš„åŠŸèƒ½ï¼šæ˜¾ç¤ºå¼•ç”¨æ¥æºã€‘ ---
            # æ£€æŸ¥æ˜¯å¦æœ‰å¼•ç”¨æº (æœ‰æ—¶å€™çº¯é—²èŠå¯èƒ½æ²¡æœ‰æº)
            if hasattr(response, 'source_nodes') and response.source_nodes:
                # ä½¿ç”¨ expander æŠ˜å èµ·æ¥ï¼Œä¿æŒç•Œé¢æç®€
                with st.expander("ğŸ“– æŸ¥çœ‹çµæ„Ÿæ¥æº (æ¥è‡ªã€Šå½“ä¸‹çš„åŠ›é‡ã€‹åŸæ–‡)"):
                    for node in response.source_nodes:
                        # æ˜¾ç¤ºç›¸ä¼¼åº¦åˆ†æ•° (Score) å’Œå…·ä½“å†…å®¹
                        # score è¶Šé«˜è¡¨ç¤ºè¶Šç›¸å…³
                        similarity = f"{node.score:.2f}" if node.score else "N/A"
                        st.markdown(f"**å…³è”åº¦:** `{similarity}`")
                        
                        # æ˜¾ç¤ºåˆ‡ç‰‡åŸæ–‡
                        st.caption(node.text) 
                        st.divider() # åˆ†å‰²çº¿

        # 3. ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²è®°å½•
        st.session_state.messages.append({"role": "assistant", "content": full_response})